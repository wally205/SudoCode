{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9538260",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:32:43.856828Z",
     "iopub.status.busy": "2025-10-12T16:32:43.856573Z",
     "iopub.status.idle": "2025-10-12T16:32:47.724614Z",
     "shell.execute_reply": "2025-10-12T16:32:47.723986Z"
    },
    "papermill": {
     "duration": 3.875461,
     "end_time": "2025-10-12T16:32:47.726123",
     "exception": false,
     "start_time": "2025-10-12T16:32:43.850662",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class EmbeddingWithProjection(nn.Module):\n",
    "    def __init__(self, vocab_size, d_embed, d_model,  \n",
    "                 max_position_embeddings =512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_embed = d_embed\n",
    "        self.vocab_size = vocab_size\n",
    "        self.embedding = nn.Embedding(self.vocab_size, self.d_embed)\n",
    "        self.projection = nn.Linear(self.d_embed, self.d_model)\n",
    "        self.scaling = float(math.sqrt(self.d_model))\n",
    "\n",
    "        self.layernorm = nn.LayerNorm(self.d_model)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_positional_encoding(seq_length, d_model, batch_size=1):\n",
    "        # Create position indices: [seq_length, 1]\n",
    "        position = torch.arange(seq_length).unsqueeze(1).float()\n",
    "        \n",
    "        # Create dimension indices: [1, d_model//2]\n",
    "        div_term = torch.exp(\n",
    "            torch.arange(0, d_model, 2).float() * \n",
    "            (-math.log(10000.0) / d_model)\n",
    "        )\n",
    "        \n",
    "        # Create empty tensor: [seq_length, d_model]\n",
    "        pe = torch.zeros(seq_length, d_model)\n",
    "        \n",
    "        # Compute sin and cos\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        \n",
    "        # Add batch dimension and expand: [batch_size, seq_length, d_model]\n",
    "        pe = pe.unsqueeze(0).expand(batch_size, -1, -1)\n",
    "        \n",
    "        return pe\n",
    "\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        assert x.dtype == torch.long, f\"Input tensor must have dtype torch.long, got {x.dtype}\"\n",
    "        batch_size, seq_length = x.size() # [batch, seq_length]\n",
    "\n",
    "        # token embedding\n",
    "        token_embedding = self.embedding(x)                                                            #[2, 16, 1024]     \n",
    "        # project the scaled token embedding to the d_model space\n",
    "        token_embedding =  self.projection(token_embedding) * self.scaling                             #[2, 16, 768]\n",
    "\n",
    "        # add positional encodings to projected, \n",
    "        # scaled embeddings before applying layer norm and dropout.\n",
    "        device = x.device  # lấy thiết bị của input (CPU/GPU)\n",
    "        positional_encoding = self.create_positional_encoding(seq_length, self.d_model, batch_size).to(device)\n",
    "            #[2, 16, 768]\n",
    "        \n",
    "        # In addition, we apply dropout to the sums of the embeddings \n",
    "        # in both the encoder and decoder stacks. For the base model, we use a rate of Pdrop = 0.1.\n",
    "        normalized_sum = self.layernorm(token_embedding + positional_encoding)\n",
    "        final_output = self.dropout(normalized_sum)\n",
    "        return final_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d60d82c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:32:47.735576Z",
     "iopub.status.busy": "2025-10-12T16:32:47.735260Z",
     "iopub.status.idle": "2025-10-12T16:32:47.746040Z",
     "shell.execute_reply": "2025-10-12T16:32:47.745248Z"
    },
    "papermill": {
     "duration": 0.017186,
     "end_time": "2025-10-12T16:32:47.747324",
     "exception": false,
     "start_time": "2025-10-12T16:32:47.730138",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerAttention(nn.Module):\n",
    "    \"\"\"\n",
    "    Transformer Scaled Dot Product Attention Module\n",
    "    Args:\n",
    "        d_model: Total dimension of the model.\n",
    "        num_head: Number of attention heads.\n",
    "        dropout: Dropout rate for attention scores.\n",
    "        bias: Whether to include bias in linear projections.\n",
    "\n",
    "    Inputs:\n",
    "        sequence: input sequence for self-attention and the query for cross-attention\n",
    "        key_value_state: input for the key, values for cross-attention\n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, num_head, dropout=0.1, bias=True): # infer d_k, d_v, d_q from d_model\n",
    "        super().__init__()  # Missing in the original implementation\n",
    "        assert d_model % num_head == 0, \"d_model must be divisible by num_head\"\n",
    "        self.d_model = d_model\n",
    "        self.num_head = num_head\n",
    "        self.d_head=d_model//num_head\n",
    "        self.dropout_rate = dropout  # Store dropout rate separately\n",
    "\n",
    "        # linear transformations\n",
    "        self.q_proj = nn.Linear(d_model, d_model, bias=bias)\n",
    "        self.k_proj = nn.Linear(d_model, d_model, bias=bias)\n",
    "        self.v_proj = nn.Linear(d_model, d_model, bias=bias)\n",
    "        self.output_proj = nn.Linear(d_model, d_model, bias=bias)\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # Initiialize scaler\n",
    "        self.scaler = float(1.0 / math.sqrt(self.d_head)) # Store as float in initialization\n",
    "        \n",
    "\n",
    "    def forward(self, sequence, key_value_states = None, att_mask=None):\n",
    "        \"\"\"Input shape: [batch_size, seq_len, d_model=num_head * d_head]\"\"\"\n",
    "        batch_size, seq_len, model_dim = sequence.size()\n",
    "\n",
    "        # Check only critical input dimensions\n",
    "        assert model_dim == self.d_model, f\"Input dimension {model_dim} doesn't match model dimension {self.d_model}\"\n",
    "        if key_value_states is not None:\n",
    "            assert key_value_states.size(-1) == self.d_model, \\\n",
    "            f\"Cross attention key/value dimension {key_value_states.size(-1)} doesn't match model dimension {self.d_model}\"\n",
    "\n",
    "\n",
    "        # if key_value_states are provided this layer is used as a cross-attention layer\n",
    "        # for the decoder\n",
    "        is_cross_attention = key_value_states is not None\n",
    "        \n",
    "        # Linear projections and reshape for multi-head\n",
    "        Q_state = self.q_proj(sequence)\n",
    "        if is_cross_attention:\n",
    "            kv_seq_len = key_value_states.size(1)\n",
    "            K_state = self.k_proj(key_value_states)\n",
    "            V_state = self.v_proj(key_value_states)\n",
    "        else:\n",
    "            kv_seq_len = seq_len\n",
    "            K_state = self.k_proj(sequence)\n",
    "            V_state = self.v_proj(sequence)\n",
    "\n",
    "        #[batch_size, self.num_head, seq_len, self.d_head]\n",
    "        Q_state = Q_state.view(batch_size, seq_len, self.num_head, self.d_head).transpose(1,2) \n",
    "            \n",
    "        # in cross-attention, key/value sequence length might be different from query sequence length\n",
    "        K_state = K_state.view(batch_size, kv_seq_len, self.num_head, self.d_head).transpose(1,2)\n",
    "        V_state = V_state.view(batch_size, kv_seq_len, self.num_head, self.d_head).transpose(1,2)\n",
    "\n",
    "        # Scale Q by 1/sqrt(d_k)\n",
    "        Q_state = Q_state * self.scaler\n",
    "    \n",
    "    \n",
    "        # Compute attention matrix: QK^T\n",
    "        self.att_matrix = torch.matmul(Q_state, K_state.transpose(-1,-2)) \n",
    "\n",
    "    \n",
    "        # apply attention mask to attention matrix\n",
    "        if att_mask is not None and not isinstance(att_mask, torch.Tensor):\n",
    "            raise TypeError(\"att_mask must be a torch.Tensor\")\n",
    "\n",
    "        if att_mask is not None:\n",
    "            self.att_matrix = self.att_matrix + att_mask\n",
    "        \n",
    "        # apply softmax to the last dimension to get the attention score: softmax(QK^T)\n",
    "        att_score = F.softmax(self.att_matrix, dim = -1)\n",
    "    \n",
    "        # apply drop out to attention score\n",
    "        att_score = self.dropout(att_score)\n",
    "    \n",
    "        # get final output: softmax(QK^T)V\n",
    "        att_output = torch.matmul(att_score, V_state)\n",
    "    \n",
    "        # concatinate all attention heads\n",
    "        att_output = att_output.transpose(1, 2)\n",
    "        att_output = att_output.contiguous().view(batch_size, seq_len, self.num_head*self.d_head) \n",
    "    \n",
    "        # final linear transformation to the concatenated output\n",
    "        att_output = self.output_proj(att_output)\n",
    "\n",
    "        assert att_output.size() == (batch_size, seq_len, self.d_model), \\\n",
    "        f\"Final output shape {att_output.size()} incorrect\"\n",
    "\n",
    "        return att_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d5afbd54",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:32:47.755328Z",
     "iopub.status.busy": "2025-10-12T16:32:47.755081Z",
     "iopub.status.idle": "2025-10-12T16:32:47.760873Z",
     "shell.execute_reply": "2025-10-12T16:32:47.760144Z"
    },
    "papermill": {
     "duration": 0.011223,
     "end_time": "2025-10-12T16:32:47.762108",
     "exception": false,
     "start_time": "2025-10-12T16:32:47.750885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    \"\"\"\n",
    "    Position-wise Feed-Forward Networks\n",
    "    This consists of two linear transformations with a ReLU activation in between.\n",
    "    \n",
    "    FFN(x) = max(0, xW1 + b1 )W2 + b2\n",
    "    d_model: embedding dimension (e.g., 512)\n",
    "    d_ff: feed-forward dimension (e.g., 2048)\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, d_model, d_ff):\n",
    "        super().__init__()\n",
    "        self.d_model=d_model\n",
    "        self.d_ff= d_ff\n",
    "        \n",
    "        # Linear transformation y = xW+b\n",
    "        self.fc1 = nn.Linear(self.d_model, self.d_ff, bias = True)\n",
    "        self.fc2 = nn.Linear(self.d_ff, self.d_model, bias = True)\n",
    "        \n",
    "        # for potential speed up\n",
    "        # Pre-normalize the weights (can help with training stability)\n",
    "        nn.init.xavier_uniform_(self.fc1.weight)\n",
    "        nn.init.xavier_uniform_(self.fc2.weight)\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        # check input and first FF layer dimension matching\n",
    "        batch_size, seq_length, d_input = input.size()\n",
    "        assert self.d_model == d_input, \"d_model must be the same dimension as the input\"\n",
    "\n",
    "        # First linear transformation followed by ReLU\n",
    "        # There's no need for explicit torch.max() as F.relu() already implements max(0,x)\n",
    "        f1 = F.relu(self.fc1(input))\n",
    "\n",
    "        # max(0, xW_1 + b_1)W_2 + b_2 \n",
    "        f2 =  self.fc2(f1)\n",
    "\n",
    "        return f2\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4e2017f2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:32:47.770158Z",
     "iopub.status.busy": "2025-10-12T16:32:47.769934Z",
     "iopub.status.idle": "2025-10-12T16:32:47.848175Z",
     "shell.execute_reply": "2025-10-12T16:32:47.847302Z"
    },
    "papermill": {
     "duration": 0.083813,
     "end_time": "2025-10-12T16:32:47.849590",
     "exception": false,
     "start_time": "2025-10-12T16:32:47.765777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerEncoder(\n",
      "  (att): TransformerAttention(\n",
      "    (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (output_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ffn): FFN(\n",
      "    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (LayerNorm_att): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (LayerNorm_ffn): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TransformerEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder layer of the Transformer\n",
    "    Sublayers: TransformerAttention\n",
    "               Residual LayerNorm\n",
    "               FNN\n",
    "               Residual LayerNorm\n",
    "    Args:\n",
    "            d_model: 512 model hidden dimension\n",
    "            d_embed: 512 embedding dimension, same as d_model in transformer framework\n",
    "            d_ff: 2048 hidden dimension of the feed forward network\n",
    "            num_head: 8 Number of attention heads.\n",
    "            dropout:  0.1 dropout rate \n",
    "            \n",
    "            bias: Whether to include bias in linear projections.\n",
    "              \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, d_model, d_ff,\n",
    "        num_head, dropout=0.1,\n",
    "        bias=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "\n",
    "        \n",
    "        # attention sublayer\n",
    "        self.att = TransformerAttention(\n",
    "            d_model = d_model,\n",
    "            num_head = num_head,\n",
    "            dropout = dropout,\n",
    "            bias = bias\n",
    "        )\n",
    "        \n",
    "        # FFN sublayer\n",
    "        self.ffn = FFN(\n",
    "            d_model = d_model,\n",
    "            d_ff = d_ff\n",
    "        )\n",
    "\n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # layer-normalization layer\n",
    "        self.LayerNorm_att = nn.LayerNorm(self.d_model)\n",
    "        self.LayerNorm_ffn = nn.LayerNorm(self.d_model)\n",
    "\n",
    "        \n",
    "    def forward(self, embed_input, padding_mask=None):\n",
    "       \n",
    "        batch_size, seq_len, _ = embed_input.size()\n",
    "        \n",
    "        ## First sublayer: self attion \n",
    "        att_sublayer = self.att(sequence = embed_input, key_value_states = None, \n",
    "                                att_mask = padding_mask)  # [batch_size, sequence_length, d_model]\n",
    "        \n",
    "        # apply dropout before layer normalization for each sublayer\n",
    "        att_sublayer = self.dropout(att_sublayer)\n",
    "        # Residual layer normalization\n",
    "        att_normalized = self.LayerNorm_att(embed_input + att_sublayer)           # [batch_size, sequence_length, d_model]\n",
    "        \n",
    "        ## Second sublayer: FFN\n",
    "        ffn_sublayer = self.ffn(att_normalized)                                   # [batch_size, sequence_length, d_model]\n",
    "        ffn_sublayer = self.dropout(ffn_sublayer)\n",
    "        ffn_normalized = self.LayerNorm_ffn(att_normalized + ffn_sublayer )       # [batch_size, sequence_length, d_model]\n",
    "    \n",
    "\n",
    "        return ffn_normalized\n",
    "net = TransformerEncoder( d_model = 512, d_ff =2048, num_head=8, dropout=0.1, bias=True )\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10bf7ba4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:32:47.858560Z",
     "iopub.status.busy": "2025-10-12T16:32:47.858319Z",
     "iopub.status.idle": "2025-10-12T16:32:47.912354Z",
     "shell.execute_reply": "2025-10-12T16:32:47.911358Z"
    },
    "papermill": {
     "duration": 0.060155,
     "end_time": "2025-10-12T16:32:47.913653",
     "exception": false,
     "start_time": "2025-10-12T16:32:47.853498",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TransformerDecoder(\n",
      "  (att): TransformerAttention(\n",
      "    (q_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (k_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (v_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (output_proj): Linear(in_features=512, out_features=512, bias=True)\n",
      "    (dropout): Dropout(p=0.1, inplace=False)\n",
      "  )\n",
      "  (ffn): FFN(\n",
      "    (fc1): Linear(in_features=512, out_features=2048, bias=True)\n",
      "    (fc2): Linear(in_features=2048, out_features=512, bias=True)\n",
      "  )\n",
      "  (dropout): Dropout(p=0.1, inplace=False)\n",
      "  (LayerNorm_att1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (LayerNorm_att2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      "  (LayerNorm_ffn): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Decoder layer of the Transformer\n",
    "    Sublayers: TransformerAttention with self-attention\n",
    "               Residual LayerNorm\n",
    "               TransformerAttention with cross-attention\n",
    "               Residual LayerNorm\n",
    "               FNN\n",
    "               Residual LayerNorm\n",
    "    Args:\n",
    "            d_model: 512 model hidden dimension\n",
    "            d_embed: 512 embedding dimension, same as d_model in transformer framework\n",
    "            d_ff: 2048 hidden dimension of the feed forward network\n",
    "            num_head: 8 Number of attention heads.\n",
    "            dropout:  0.1 dropout rate \n",
    "            \n",
    "            bias: Whether to include bias in linear projections.\n",
    "              \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self, d_model, d_ff,\n",
    "        num_head, dropout=0.1,\n",
    "        bias=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "\n",
    "        \n",
    "        # attention sublayer\n",
    "        self.att = TransformerAttention(\n",
    "            d_model = d_model,\n",
    "            num_head = num_head,\n",
    "            dropout = dropout,\n",
    "            bias = bias\n",
    "        )\n",
    "        \n",
    "        # FFN sublayer\n",
    "        self.ffn = FFN(\n",
    "            d_model = d_model,\n",
    "            d_ff = d_ff\n",
    "        )\n",
    "\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "\n",
    "        # layer-normalization layer\n",
    "        self.LayerNorm_att1 = nn.LayerNorm(self.d_model)\n",
    "        self.LayerNorm_att2 = nn.LayerNorm(self.d_model)\n",
    "        self.LayerNorm_ffn = nn.LayerNorm(self.d_model)\n",
    "\n",
    "    @staticmethod\n",
    "    def create_causal_mask(seq_len):\n",
    "        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1)\n",
    "        mask = mask.masked_fill(mask == 1, float('-inf'))\n",
    "        return mask\n",
    "\n",
    "    \n",
    "    def forward(self, embed_input, cross_input, padding_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        embed_input: Decoder input sequence [batch_size, seq_len, d_model]\n",
    "        cross_input: Encoder output sequence [batch_size, encoder_seq_len, d_model]\n",
    "        casual_attention_mask: Causal mask for self-attention [batch_size, seq_len, seq_len]\n",
    "        padding_mask: Padding mask for cross-attention [batch_size, seq_len, encoder_seq_len]\n",
    "        Returns:\n",
    "        Tensor: Decoded output [batch_size, seq_len, d_model]\n",
    "        \"\"\"\n",
    "        batch_size, seq_len, _ = embed_input.size()\n",
    "        \n",
    "        assert embed_input.size(-1) == self.d_model, f\"Input dimension {embed_input.size(-1)} doesn't match model dimension {self.d_model}\"\n",
    "        assert cross_input.size(-1) == self.d_model, \"Encoder output dimension doesn't match model dimension\"\n",
    "\n",
    "\n",
    "        # Generate and expand causal mask for self-attention\n",
    "        causal_mask = self.create_causal_mask(seq_len).to(embed_input.device)  # [seq_len, seq_len]\n",
    "        causal_mask = causal_mask.unsqueeze(0).unsqueeze(1)  # [1, 1, seq_len, seq_len]\n",
    "\n",
    "\n",
    "        ## First sublayer: self attion \n",
    "        # After embedding and positional encoding, input sequence feed into current attention sublayer\n",
    "        # Or, the output of the previous encoder/decoder feed into current attention sublayer\n",
    "        att_sublayer1 = self.att(sequence = embed_input, key_value_states = None, \n",
    "                                att_mask = causal_mask)  # [batch_size, num_head, sequence_length, d_model]\n",
    "        # apply dropout before layer normalization for each sublayer\n",
    "        att_sublayer1 = self.dropout(att_sublayer1)\n",
    "        # Residual layer normalization\n",
    "        att_normalized1 = self.LayerNorm_att1(embed_input + att_sublayer1)           # [batch_size, sequence_length, d_model]\n",
    "\n",
    "        ## Second sublayer: cross attention\n",
    "        # Query from the output of previous attention output, or training data\n",
    "        # Key, Value from output of Encoder of the same layer\n",
    "        att_sublayer2 = self.att(sequence = att_normalized1, key_value_states = cross_input, \n",
    "                                att_mask = padding_mask)  # [batch_size, sequence_length, d_model]\n",
    "        # apply dropout before layer normalization for each sublayer\n",
    "        att_sublayer2 = self.dropout(att_sublayer2)\n",
    "        # Residual layer normalization\n",
    "        att_normalized2 = self.LayerNorm_att2(att_normalized1 + att_sublayer2)           # [batch_size, sequence_length, d_model]\n",
    "        \n",
    "        \n",
    "        # Third sublayer: FFN\n",
    "        ffn_sublayer = self.ffn(att_normalized2)                                   # [batch_size, sequence_length, d_model]\n",
    "        ffn_sublayer = self.dropout(ffn_sublayer)\n",
    "        ffn_normalized = self.LayerNorm_ffn(att_normalized2 + ffn_sublayer )       # [batch_size, sequence_length, d_model]\n",
    "    \n",
    "\n",
    "        return ffn_normalized\n",
    "net = TransformerDecoder( d_model = 512, d_ff =2048, num_head=8, dropout=0.1, bias=True )\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8379705b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:32:47.921967Z",
     "iopub.status.busy": "2025-10-12T16:32:47.921707Z",
     "iopub.status.idle": "2025-10-12T16:32:47.928027Z",
     "shell.execute_reply": "2025-10-12T16:32:47.927536Z"
    },
    "papermill": {
     "duration": 0.011744,
     "end_time": "2025-10-12T16:32:47.929140",
     "exception": false,
     "start_time": "2025-10-12T16:32:47.917396",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TransformerEncoderDecoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Encoder-Decoder stack of the Transformer\n",
    "    Sublayers:  Encoder x 6\n",
    "                Decoder x 6\n",
    "    Args:\n",
    "            d_model: 512 model hidden dimension\n",
    "            d_embed: 512 embedding dimension, same as d_model in transformer framework\n",
    "            d_ff: 2048 hidden dimension of the feed forward network\n",
    "            num_head: 8 Number of attention heads.\n",
    "            dropout:  0.1 dropout rate \n",
    "            \n",
    "            bias: Whether to include bias in linear projections.\n",
    "              \n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, num_layer,\n",
    "        d_model, d_ff,\n",
    "        num_head, dropout=0.1,\n",
    "        bias=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.num_layer = num_layer\n",
    "        self.d_model = d_model\n",
    "        self.d_ff = d_ff\n",
    "        self.num_head = num_head\n",
    "        self.dropout = dropout\n",
    "        self.bias = bias\n",
    "        \n",
    "        # Encoder stack\n",
    "        self.encoder_stack = nn.ModuleList([ TransformerEncoder(\n",
    "                                        d_model = self.d_model, \n",
    "                                        d_ff = self.d_ff,\n",
    "                                        num_head = self.num_head, \n",
    "                                        dropout = self.dropout,\n",
    "                                        bias = self.bias) for _ in range(self.num_layer)])\n",
    "\n",
    "        # Decoder stack\n",
    "        self.decoder_stack = nn.ModuleList([ TransformerDecoder(\n",
    "                                        d_model = self.d_model, \n",
    "                                        d_ff = self.d_ff,\n",
    "                                        num_head = self.num_head, \n",
    "                                        dropout = self.dropout,\n",
    "                                        bias = self.bias) for _ in range(self.num_layer)])\n",
    "\n",
    "    \n",
    "    def forward(self, embed_encoder_input, embed_decoder_input, padding_mask=None):\n",
    "        # Process through all encoder layers first\n",
    "        encoder_output = embed_encoder_input\n",
    "        for encoder in self.encoder_stack:\n",
    "            encoder_output = encoder(encoder_output, padding_mask)\n",
    "        \n",
    "        # Use final encoder output for all decoder layers\n",
    "        decoder_output = embed_decoder_input\n",
    "        for decoder in self.decoder_stack:\n",
    "            decoder_output = decoder(decoder_output, encoder_output, padding_mask)\n",
    "        \n",
    "        return decoder_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea8cfda4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:32:47.937508Z",
     "iopub.status.busy": "2025-10-12T16:32:47.937297Z",
     "iopub.status.idle": "2025-10-12T16:32:47.944556Z",
     "shell.execute_reply": "2025-10-12T16:32:47.943873Z"
    },
    "papermill": {
     "duration": 0.012853,
     "end_time": "2025-10-12T16:32:47.945738",
     "exception": false,
     "start_time": "2025-10-12T16:32:47.932885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        num_layer,\n",
    "        d_model, d_embed, d_ff,\n",
    "        num_head,\n",
    "        src_vocab_size, \n",
    "        tgt_vocab_size,\n",
    "        max_position_embeddings=512,\n",
    "        dropout=0.1,\n",
    "        bias=True\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.tgt_vocab_size = tgt_vocab_size\n",
    "        \n",
    "        # Source and target embeddings\n",
    "        self.src_embedding = EmbeddingWithProjection(\n",
    "            vocab_size=src_vocab_size,\n",
    "            d_embed=d_embed,\n",
    "            d_model=d_model,\n",
    "            max_position_embeddings=max_position_embeddings,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        self.tgt_embedding = EmbeddingWithProjection(\n",
    "            vocab_size=tgt_vocab_size,\n",
    "            d_embed=d_embed,\n",
    "            d_model=d_model,\n",
    "            max_position_embeddings=max_position_embeddings,\n",
    "            dropout=dropout\n",
    "        )\n",
    "        \n",
    "        # Encoder-Decoder stack\n",
    "        self.encoder_decoder = TransformerEncoderDecoder(\n",
    "            num_layer=num_layer,\n",
    "            d_model=d_model,\n",
    "            d_ff=d_ff,\n",
    "            num_head=num_head,\n",
    "            dropout=dropout,\n",
    "            bias=bias\n",
    "        )\n",
    "        \n",
    "        # Output projection and softmax\n",
    "        self.output_projection = nn.Linear(d_model, tgt_vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=-1)\n",
    "        \n",
    "    def shift_target_right(self, tgt_tokens):\n",
    "        # Shift target tokens right by padding with zeros at the beginning\n",
    "        batch_size, seq_len = tgt_tokens.size()\n",
    "        \n",
    "        # Create start token (zeros)\n",
    "        start_tokens = torch.zeros(batch_size, 1, dtype=tgt_tokens.dtype, device=tgt_tokens.device)\n",
    "        \n",
    "        # Concatenate start token and remove last token\n",
    "        shifted_tokens = torch.cat([start_tokens, tgt_tokens[:, :-1]], dim=1)\n",
    "        \n",
    "        return shifted_tokens\n",
    "        \n",
    "    def forward(self, src_tokens, tgt_tokens, padding_mask=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            src_tokens: source sequence [batch_size, src_len]\n",
    "            tgt_tokens: target sequence [batch_size, tgt_len]\n",
    "            padding_mask: padding mask [batch_size, 1, 1, seq_len]\n",
    "        Returns:\n",
    "            output: [batch_size, tgt_len, tgt_vocab_size] log probabilities\n",
    "        \"\"\"\n",
    "        # Shift target tokens right for teacher forcing\n",
    "        shifted_tgt_tokens = self.shift_target_right(tgt_tokens)\n",
    "        \n",
    "        # Embed source and target sequences\n",
    "        src_embedding = self.src_embedding(src_tokens)\n",
    "        tgt_embedding = self.tgt_embedding(shifted_tgt_tokens)\n",
    "        \n",
    "        # Pass through encoder-decoder stack\n",
    "        decoder_output = self.encoder_decoder(\n",
    "            embed_encoder_input=src_embedding,\n",
    "            embed_decoder_input=tgt_embedding,\n",
    "            padding_mask=padding_mask\n",
    "        )\n",
    "        \n",
    "        # Project to vocabulary size and apply log softmax\n",
    "        logits = self.output_projection(decoder_output)\n",
    "        log_probs = self.softmax(logits)\n",
    "        \n",
    "        return log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9837f6bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:32:47.954154Z",
     "iopub.status.busy": "2025-10-12T16:32:47.953892Z",
     "iopub.status.idle": "2025-10-12T16:32:55.700044Z",
     "shell.execute_reply": "2025-10-12T16:32:55.699110Z"
    },
    "papermill": {
     "duration": 7.75201,
     "end_time": "2025-10-12T16:32:55.701430",
     "exception": false,
     "start_time": "2025-10-12T16:32:47.949420",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số cặp câu trích xuất: 45308\n",
      "Train/Val/Test: 44402 / 453 / 453\n",
      "Dữ liệu đã lưu trong: /kaggle/working/processed_evbcorpus\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "from pathlib import Path\n",
    "from random import Random\n",
    "\n",
    "BASE_PATH = \"/kaggle/input/evb-corpus-news/EVBCorpus_v1/EVBNews\"\n",
    "OUT_DIR = Path(\"processed_evbcorpus\")\n",
    "OUT_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "def extract_pairs(file_path):\n",
    "    \"\"\"Trích xuất các cặp câu song ngữ <s id='en...'> và <s id='vn...'>\"\"\"\n",
    "    text = Path(file_path).read_text(encoding=\"utf-8\", errors=\"ignore\")\n",
    "\n",
    "    en_sentences = re.findall(r\"<s id='en\\d+'>(.*?)</s>\", text, flags=re.DOTALL)\n",
    "    vi_sentences = re.findall(r\"<s id='vn\\d+'>(.*?)</s>\", text, flags=re.DOTALL)\n",
    "\n",
    "    pairs = []\n",
    "    for en, vi in zip(en_sentences, vi_sentences):\n",
    "        en = \" \".join(en.strip().split())\n",
    "        vi = \" \".join(vi.strip().split())\n",
    "        if en and vi:\n",
    "            pairs.append((en, vi))\n",
    "    return pairs\n",
    "\n",
    "all_pairs = []\n",
    "for filename in sorted(os.listdir(BASE_PATH)):\n",
    "    if filename.endswith(\".sgml\"):\n",
    "        file_path = os.path.join(BASE_PATH, filename)\n",
    "        all_pairs.extend(extract_pairs(file_path))\n",
    "\n",
    "print(f\"Tổng số cặp câu trích xuất: {len(all_pairs)}\")\n",
    "\n",
    "rnd = Random(42)\n",
    "rnd.shuffle(all_pairs)\n",
    "n = len(all_pairs)\n",
    "n_val = int(0.01 * n)\n",
    "n_test = int(0.01 * n)\n",
    "\n",
    "train_pairs = all_pairs[: n - n_val - n_test]\n",
    "val_pairs = all_pairs[n - n_val - n_test : n - n_test]\n",
    "test_pairs = all_pairs[n - n_test :]\n",
    "\n",
    "def write_split(pairs, prefix):\n",
    "    src_path = OUT_DIR / f\"{prefix}.en\"\n",
    "    tgt_path = OUT_DIR / f\"{prefix}.vi\"\n",
    "    with open(src_path, \"w\", encoding=\"utf-8\") as fe, open(tgt_path, \"w\", encoding=\"utf-8\") as fv:\n",
    "        for src, tgt in pairs:\n",
    "            fe.write(src + \"\\n\")\n",
    "            fv.write(tgt + \"\\n\")\n",
    "\n",
    "write_split(train_pairs, \"train\")\n",
    "write_split(val_pairs, \"val\")\n",
    "write_split(test_pairs, \"test\")\n",
    "\n",
    "print(f\"Train/Val/Test: {len(train_pairs)} / {len(val_pairs)} / {len(test_pairs)}\")\n",
    "print(f\"Dữ liệu đã lưu trong: {OUT_DIR.resolve()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1791c85a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:32:55.710227Z",
     "iopub.status.busy": "2025-10-12T16:32:55.709879Z",
     "iopub.status.idle": "2025-10-12T16:33:13.623794Z",
     "shell.execute_reply": "2025-10-12T16:33:13.622760Z"
    },
    "papermill": {
     "duration": 17.92004,
     "end_time": "2025-10-12T16:33:13.625494",
     "exception": false,
     "start_time": "2025-10-12T16:32:55.705454",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.5/9.5 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m564.3/564.3 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.8/42.8 MB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m93.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\r\n",
      "pylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\r\n",
      "cudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 21.0.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires google-cloud-bigquery[bqstorage,pandas]>=3.31.0, but you have google-cloud-bigquery 3.25.0 which is incompatible.\r\n",
      "bigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.1.0 which is incompatible.\r\n",
      "gradio 5.38.1 requires pydantic<2.12,>=2.0, but you have pydantic 2.12.0a1 which is incompatible.\r\n",
      "cudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\r\n",
      "pandas-gbq 0.29.2 requires google-api-core<3.0.0,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\u001b[0m\u001b[31m\r\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers==4.44.2 datasets tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c99089cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:33:13.636164Z",
     "iopub.status.busy": "2025-10-12T16:33:13.635438Z",
     "iopub.status.idle": "2025-10-12T16:33:14.173126Z",
     "shell.execute_reply": "2025-10-12T16:33:14.172443Z"
    },
    "papermill": {
     "duration": 0.544274,
     "end_time": "2025-10-12T16:33:14.174457",
     "exception": false,
     "start_time": "2025-10-12T16:33:13.630183",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import AutoTokenizer\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e1667e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:33:14.185408Z",
     "iopub.status.busy": "2025-10-12T16:33:14.185160Z",
     "iopub.status.idle": "2025-10-12T16:33:17.194227Z",
     "shell.execute_reply": "2025-10-12T16:33:17.193447Z"
    },
    "papermill": {
     "duration": 3.01608,
     "end_time": "2025-10-12T16:33:17.195617",
     "exception": false,
     "start_time": "2025-10-12T16:33:14.179537",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4fe5d3c2b76a48bfaed7514e1ca11d5b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca002b9787314d17820f38dc99cfba38",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "437819c274b54b7e8232a42bb7a870da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee4af5d472d447fb712e009774372b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\")\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "#Dataset\n",
    "class TranslationDataset(Dataset):\n",
    "    def __init__(self, src_path, tgt_path, tokenizer, max_len=64):\n",
    "        self.src_texts = open(src_path, encoding=\"utf-8\").read().strip().split(\"\\n\")\n",
    "        self.tgt_texts = open(tgt_path, encoding=\"utf-8\").read().strip().split(\"\\n\")\n",
    "        assert len(self.src_texts) == len(self.tgt_texts), \"⚠️ Số dòng src/tgt không khớp!\"\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.src_texts)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        src = self.src_texts[idx]\n",
    "        tgt = self.tgt_texts[idx]\n",
    "\n",
    "        src_enc = self.tokenizer(src, truncation=True, max_length=self.max_len, return_tensors=\"pt\")\n",
    "        tgt_enc = self.tokenizer(tgt, truncation=True, max_length=self.max_len, return_tensors=\"pt\")\n",
    "\n",
    "        return {\n",
    "            \"src_input\": src_enc[\"input_ids\"].squeeze(0),\n",
    "            \"tgt_input\": tgt_enc[\"input_ids\"].squeeze(0),\n",
    "            \"tgt_label\": tgt_enc[\"input_ids\"].squeeze(0),\n",
    "        }\n",
    "\n",
    "#Collate function\n",
    "def collate_fn(batch):\n",
    "    src_batch = [item[\"src_input\"] for item in batch]\n",
    "    tgt_batch = [item[\"tgt_input\"] for item in batch]\n",
    "    label_batch = [item[\"tgt_label\"] for item in batch]\n",
    "\n",
    "    src_batch = torch.nn.utils.rnn.pad_sequence(src_batch, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    tgt_batch = torch.nn.utils.rnn.pad_sequence(tgt_batch, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "    label_batch = torch.nn.utils.rnn.pad_sequence(label_batch, batch_first=True, padding_value=tokenizer.pad_token_id)\n",
    "\n",
    "    return {\n",
    "        \"src_input\": src_batch,\n",
    "        \"tgt_input\": tgt_batch,\n",
    "        \"tgt_label\": label_batch\n",
    "    }\n",
    "\n",
    "# Dataloader\n",
    "train_dataset = TranslationDataset(\"processed_evbcorpus/train.en\", \"processed_evbcorpus/train.vi\", tokenizer)\n",
    "val_dataset = TranslationDataset(\"processed_evbcorpus/val.en\", \"processed_evbcorpus/val.vi\", tokenizer)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, collate_fn=collate_fn)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, collate_fn=collate_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0393a976",
   "metadata": {},
   "source": [
    "Config 1: d_model=128, embed=128, num_layer=4, 50 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "472a9a9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T16:33:17.206883Z",
     "iopub.status.busy": "2025-10-12T16:33:17.206608Z",
     "iopub.status.idle": "2025-10-12T20:49:35.528968Z",
     "shell.execute_reply": "2025-10-12T20:49:35.528043Z"
    },
    "papermill": {
     "duration": 15378.329317,
     "end_time": "2025-10-12T20:49:35.530253",
     "exception": false,
     "start_time": "2025-10-12T16:33:17.200936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 2776/2776 [05:08<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 1 | Train Loss: 6.4927 | Val Loss: 6.0462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 2776/2776 [05:03<00:00,  9.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 2 | Train Loss: 5.9541 | Val Loss: 5.7784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 2776/2776 [05:03<00:00,  9.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 3 | Train Loss: 5.7236 | Val Loss: 5.5940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 2776/2776 [05:03<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 4 | Train Loss: 5.5482 | Val Loss: 5.5053\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 2776/2776 [05:04<00:00,  9.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 5 | Train Loss: 5.4039 | Val Loss: 5.3935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 2776/2776 [05:03<00:00,  9.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 6 | Train Loss: 5.2893 | Val Loss: 5.3416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 2776/2776 [05:05<00:00,  9.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 7 | Train Loss: 5.1914 | Val Loss: 5.3137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 2776/2776 [05:04<00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 8 | Train Loss: 5.1083 | Val Loss: 5.2451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2776/2776 [05:06<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 9 | Train Loss: 5.0315 | Val Loss: 5.1856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 2776/2776 [05:07<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 10 | Train Loss: 4.9644 | Val Loss: 5.1498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 2776/2776 [05:07<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 11 | Train Loss: 4.8986 | Val Loss: 5.1124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 2776/2776 [05:07<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 12 | Train Loss: 4.8382 | Val Loss: 5.0575\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 2776/2776 [05:06<00:00,  9.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 13 | Train Loss: 4.7733 | Val Loss: 5.0060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 2776/2776 [05:04<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 14 | Train Loss: 4.7144 | Val Loss: 4.9684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 2776/2776 [05:02<00:00,  9.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 15 | Train Loss: 4.6577 | Val Loss: 4.9554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 2776/2776 [05:03<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 16 | Train Loss: 4.6049 | Val Loss: 4.8696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 2776/2776 [05:05<00:00,  9.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 17 | Train Loss: 4.5552 | Val Loss: 4.8466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 2776/2776 [05:07<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 18 | Train Loss: 4.5077 | Val Loss: 4.8064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 2776/2776 [05:07<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 19 | Train Loss: 4.4645 | Val Loss: 4.7813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 2776/2776 [05:07<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 20 | Train Loss: 4.4206 | Val Loss: 4.7279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 2776/2776 [05:08<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 21 | Train Loss: 4.3804 | Val Loss: 4.7144\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 2776/2776 [05:07<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 22 | Train Loss: 4.3432 | Val Loss: 4.6962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 2776/2776 [05:05<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 23 | Train Loss: 4.3029 | Val Loss: 4.6380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 2776/2776 [05:03<00:00,  9.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 24 | Train Loss: 4.2698 | Val Loss: 4.6262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 25: 100%|██████████| 2776/2776 [05:04<00:00,  9.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 25 | Train Loss: 4.2355 | Val Loss: 4.6026\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 26: 100%|██████████| 2776/2776 [05:07<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 26 | Train Loss: 4.2035 | Val Loss: 4.5366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 27: 100%|██████████| 2776/2776 [05:07<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 27 | Train Loss: 4.1723 | Val Loss: 4.5481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 28: 100%|██████████| 2776/2776 [05:07<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 28 | Train Loss: 4.1415 | Val Loss: 4.5097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 29: 100%|██████████| 2776/2776 [05:07<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 29 | Train Loss: 4.1140 | Val Loss: 4.4846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 30: 100%|██████████| 2776/2776 [05:04<00:00,  9.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 30 | Train Loss: 4.0892 | Val Loss: 4.4458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 31: 100%|██████████| 2776/2776 [05:07<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 31 | Train Loss: 4.0625 | Val Loss: 4.4787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 32: 100%|██████████| 2776/2776 [05:08<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 32 | Train Loss: 4.0378 | Val Loss: 4.4252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 33: 100%|██████████| 2776/2776 [05:06<00:00,  9.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 33 | Train Loss: 4.0119 | Val Loss: 4.3964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 34: 100%|██████████| 2776/2776 [05:07<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 34 | Train Loss: 3.9875 | Val Loss: 4.3945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 35: 100%|██████████| 2776/2776 [05:07<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 35 | Train Loss: 3.9657 | Val Loss: 4.3699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 36: 100%|██████████| 2776/2776 [05:06<00:00,  9.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 36 | Train Loss: 3.9458 | Val Loss: 4.3687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 37: 100%|██████████| 2776/2776 [05:07<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 37 | Train Loss: 3.9239 | Val Loss: 4.3472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 38: 100%|██████████| 2776/2776 [05:07<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 38 | Train Loss: 3.9017 | Val Loss: 4.3274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 39: 100%|██████████| 2776/2776 [05:05<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 39 | Train Loss: 3.8839 | Val Loss: 4.2925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 40: 100%|██████████| 2776/2776 [05:05<00:00,  9.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 40 | Train Loss: 3.8641 | Val Loss: 4.2576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 41: 100%|██████████| 2776/2776 [05:04<00:00,  9.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 41 | Train Loss: 3.8458 | Val Loss: 4.2479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 42: 100%|██████████| 2776/2776 [05:05<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 42 | Train Loss: 3.8261 | Val Loss: 4.2801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 43: 100%|██████████| 2776/2776 [05:07<00:00,  9.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 43 | Train Loss: 3.8084 | Val Loss: 4.2282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 44: 100%|██████████| 2776/2776 [05:06<00:00,  9.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 44 | Train Loss: 3.7924 | Val Loss: 4.2047\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 45: 100%|██████████| 2776/2776 [05:07<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 45 | Train Loss: 3.7746 | Val Loss: 4.2022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 46: 100%|██████████| 2776/2776 [05:07<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 46 | Train Loss: 3.7586 | Val Loss: 4.1663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 47: 100%|██████████| 2776/2776 [05:07<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 47 | Train Loss: 3.7437 | Val Loss: 4.2019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 48: 100%|██████████| 2776/2776 [05:07<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 48 | Train Loss: 3.7291 | Val Loss: 4.1497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 2776/2776 [05:07<00:00,  9.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 49 | Train Loss: 3.7140 | Val Loss: 4.1747\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 50: 100%|██████████| 2776/2776 [05:05<00:00,  9.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch 50 | Train Loss: 3.7009 | Val Loss: 4.1339\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(tokenizer)\n",
    "tgt_vocab_size = len(tokenizer)\n",
    "\n",
    "model = Transformer(\n",
    "    num_layer=4,\n",
    "    d_model=128,\n",
    "    d_embed=128,\n",
    "    d_ff=256,\n",
    "    num_head=8,\n",
    "    src_vocab_size=src_vocab_size,\n",
    "    tgt_vocab_size=tgt_vocab_size,\n",
    "    dropout=0.2\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "#Loss + Optimizer\n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "#Training Loop\n",
    "for epoch in range(50):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        src = batch[\"src_input\"].to(device)\n",
    "        tgt_out = batch[\"tgt_label\"].to(device)\n",
    "        tgt_in = tgt_out[:, :-1]\n",
    "        labels = tgt_out[:, 1:]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt_in)  \n",
    "        loss = criterion(output.reshape(-1, output.size(-1)), labels.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            src = batch[\"src_input\"].to(device)\n",
    "            tgt_out = batch[\"tgt_label\"].to(device)\n",
    "            tgt_in = tgt_out[:, :-1]\n",
    "            labels = tgt_out[:, 1:]\n",
    "            output = model(src, tgt_in)\n",
    "            loss = criterion(output.reshape(-1, output.size(-1)), labels.reshape(-1))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    print(f\" Epoch {epoch+1} | Train Loss: {total_loss/len(train_loader):.4f} | Val Loss: {val_loss/len(val_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8568eb95",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T20:49:46.257134Z",
     "iopub.status.busy": "2025-10-12T20:49:46.256307Z",
     "iopub.status.idle": "2025-10-12T20:49:47.470895Z",
     "shell.execute_reply": "2025-10-12T20:49:47.470078Z"
    },
    "papermill": {
     "duration": 6.584602,
     "end_time": "2025-10-12T20:49:47.472306",
     "exception": false,
     "start_time": "2025-10-12T20:49:40.887704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 29/29 [00:01<00:00, 24.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Loss: 4.0633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ===== 8. Test Evaluation =====\n",
    "test_dataset = TranslationDataset(\n",
    "    \"processed_evbcorpus/test.en\", \"processed_evbcorpus/test.vi\", tokenizer\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=collate_fn)\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "        src = batch[\"src_input\"].to(device)\n",
    "        tgt_out = batch[\"tgt_label\"].to(device)\n",
    "        tgt_in = tgt_out[:, :-1]\n",
    "        labels = tgt_out[:, 1:]\n",
    "\n",
    "        output = model(src, tgt_in)\n",
    "        loss = criterion(output.reshape(-1, output.size(-1)), labels.reshape(-1))\n",
    "        test_loss += loss.item()\n",
    "\n",
    "print(f\" Test Loss: {test_loss / len(test_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2956cc30",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T20:49:58.390413Z",
     "iopub.status.busy": "2025-10-12T20:49:58.389655Z",
     "iopub.status.idle": "2025-10-12T20:49:58.395278Z",
     "shell.execute_reply": "2025-10-12T20:49:58.394610Z"
    },
    "papermill": {
     "duration": 5.465126,
     "end_time": "2025-10-12T20:49:58.396555",
     "exception": false,
     "start_time": "2025-10-12T20:49:52.931429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def translate(sentence, max_len=64):\n",
    "    model.eval()\n",
    "    tokens = tokenizer(sentence, return_tensors=\"pt\", truncation=True, max_length=max_len).to(device)\n",
    "\n",
    "    src = tokens[\"input_ids\"]\n",
    "\n",
    "    tgt = torch.tensor([[tokenizer.cls_token_id]], device=device)\n",
    "\n",
    "    for _ in range(max_len):\n",
    "        with torch.no_grad():\n",
    "            out = model(src, tgt)\n",
    "            next_token = out[:, -1, :].argmax(dim=-1)\n",
    "            tgt = torch.cat([tgt, next_token.unsqueeze(0)], dim=1)\n",
    "            if next_token.item() == tokenizer.sep_token_id:\n",
    "                break\n",
    "\n",
    "    decoded = tokenizer.decode(tgt[0], skip_special_tokens=True)\n",
    "    return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f06055e2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T20:50:09.231666Z",
     "iopub.status.busy": "2025-10-12T20:50:09.231390Z",
     "iopub.status.idle": "2025-10-12T20:50:12.944329Z",
     "shell.execute_reply": "2025-10-12T20:50:12.943482Z"
    },
    "papermill": {
     "duration": 9.154382,
     "end_time": "2025-10-12T20:50:12.945870",
     "exception": false,
     "start_time": "2025-10-12T20:50:03.791488",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25h"
     ]
    }
   ],
   "source": [
    "!pip install -q sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a8aae26",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T20:50:23.799565Z",
     "iopub.status.busy": "2025-10-12T20:50:23.799253Z",
     "iopub.status.idle": "2025-10-12T20:52:54.149913Z",
     "shell.execute_reply": "2025-10-12T20:52:54.149079Z"
    },
    "papermill": {
     "duration": 159.868382,
     "end_time": "2025-10-12T20:52:58.456999",
     "exception": false,
     "start_time": "2025-10-12T20:50:18.588617",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating BLEU: 100%|██████████| 29/29 [02:30<00:00,  5.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BLEU score: 1.08\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "\n",
    "references, hypotheses = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Evaluating BLEU\"):\n",
    "        src_texts = [tokenizer.decode(x, skip_special_tokens=True) for x in batch[\"src_input\"]]\n",
    "        tgt_texts = [tokenizer.decode(x, skip_special_tokens=True) for x in batch[\"tgt_label\"]]\n",
    "\n",
    "        for s, t in zip(src_texts, tgt_texts):\n",
    "            pred = translate(s)\n",
    "            references.append(t)\n",
    "            hypotheses.append(pred)\n",
    "\n",
    "bleu = sacrebleu.corpus_bleu(hypotheses, [references])\n",
    "print(f\" BLEU score: {bleu.score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d53cc81",
   "metadata": {},
   "source": [
    "config 2: d_model=256, d_embed=256, num_layer=4, 20 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "967180e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T20:53:09.239613Z",
     "iopub.status.busy": "2025-10-12T20:53:09.238703Z",
     "iopub.status.idle": "2025-10-12T23:17:45.638521Z",
     "shell.execute_reply": "2025-10-12T23:17:45.637539Z"
    },
    "papermill": {
     "duration": 8682.181031,
     "end_time": "2025-10-12T23:17:46.191577",
     "exception": false,
     "start_time": "2025-10-12T20:53:04.010546",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 2776/2776 [07:14<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 6.2924 | Val Loss: 5.8048\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 2776/2776 [07:13<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 5.6650 | Val Loss: 5.5249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 2776/2776 [07:14<00:00,  6.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 5.3549 | Val Loss: 5.3206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 2776/2776 [07:15<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 5.1333 | Val Loss: 5.1909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 2776/2776 [07:15<00:00,  6.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 4.9569 | Val Loss: 5.1062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 2776/2776 [07:14<00:00,  6.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 4.8068 | Val Loss: 4.9955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 2776/2776 [07:12<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 4.6831 | Val Loss: 4.9417\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 2776/2776 [07:12<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 4.5755 | Val Loss: 4.8872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 2776/2776 [07:13<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 4.4778 | Val Loss: 4.8614\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 2776/2776 [07:12<00:00,  6.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 4.3955 | Val Loss: 4.8018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 2776/2776 [07:13<00:00,  6.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 4.3186 | Val Loss: 4.7706\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 2776/2776 [07:11<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12 | Train Loss: 4.2512 | Val Loss: 4.7382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 2776/2776 [07:11<00:00,  6.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13 | Train Loss: 4.1900 | Val Loss: 4.7155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 2776/2776 [07:10<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14 | Train Loss: 4.1340 | Val Loss: 4.6885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 2776/2776 [07:09<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15 | Train Loss: 4.0839 | Val Loss: 4.6676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 2776/2776 [07:09<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16 | Train Loss: 4.0361 | Val Loss: 4.6512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 2776/2776 [07:09<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17 | Train Loss: 3.9935 | Val Loss: 4.6636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 2776/2776 [07:09<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18 | Train Loss: 3.9523 | Val Loss: 4.6194\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 2776/2776 [07:09<00:00,  6.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19 | Train Loss: 3.9146 | Val Loss: 4.6218\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 2776/2776 [07:10<00:00,  6.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20 | Train Loss: 3.8795 | Val Loss: 4.5935\n"
     ]
    }
   ],
   "source": [
    "src_vocab_size = len(tokenizer)\n",
    "tgt_vocab_size = len(tokenizer)\n",
    "\n",
    "model = Transformer(\n",
    "    num_layer=4,\n",
    "    d_model=256,\n",
    "    d_embed=256,\n",
    "    d_ff=512,\n",
    "    num_head=8,\n",
    "    src_vocab_size=src_vocab_size,\n",
    "    tgt_vocab_size=tgt_vocab_size,\n",
    "    dropout=0.2\n",
    ")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Loss + Optimizer \n",
    "criterion = torch.nn.CrossEntropyLoss(ignore_index=tokenizer.pad_token_id)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "\n",
    "# Training Loop \n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Epoch {epoch+1}\"):\n",
    "        src = batch[\"src_input\"].to(device)\n",
    "        tgt_out = batch[\"tgt_label\"].to(device)\n",
    "\n",
    "        tgt_in = tgt_out[:, :-1]\n",
    "        labels = tgt_out[:, 1:]\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output = model(src, tgt_in) \n",
    "        loss = criterion(output.reshape(-1, output.size(-1)), labels.reshape(-1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in val_loader:\n",
    "            src = batch[\"src_input\"].to(device)\n",
    "            tgt_out = batch[\"tgt_label\"].to(device)\n",
    "            tgt_in = tgt_out[:, :-1]\n",
    "            labels = tgt_out[:, 1:]\n",
    "            output = model(src, tgt_in)\n",
    "            loss = criterion(output.reshape(-1, output.size(-1)), labels.reshape(-1))\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1} | Train Loss: {total_loss/len(train_loader):.4f} | Val Loss: {val_loss/len(val_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d028bae1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T23:18:01.600231Z",
     "iopub.status.busy": "2025-10-12T23:18:01.599590Z",
     "iopub.status.idle": "2025-10-12T23:18:03.118432Z",
     "shell.execute_reply": "2025-10-12T23:18:03.117620Z"
    },
    "papermill": {
     "duration": 9.304787,
     "end_time": "2025-10-12T23:18:03.119701",
     "exception": false,
     "start_time": "2025-10-12T23:17:53.814914",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 29/29 [00:01<00:00, 19.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Test Loss: 4.6238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Test Evaluation\n",
    "test_dataset = TranslationDataset(\n",
    "    \"processed_evbcorpus/test.en\", \"processed_evbcorpus/test.vi\", tokenizer\n",
    ")\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, collate_fn=collate_fn)\n",
    "\n",
    "model.eval()\n",
    "test_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "        src = batch[\"src_input\"].to(device)\n",
    "        tgt_out = batch[\"tgt_label\"].to(device)\n",
    "        tgt_in = tgt_out[:, :-1]\n",
    "        labels = tgt_out[:, 1:]\n",
    "\n",
    "        output = model(src, tgt_in)\n",
    "        loss = criterion(output.reshape(-1, output.size(-1)), labels.reshape(-1))\n",
    "        test_loss += loss.item()\n",
    "\n",
    "print(f\" Test Loss: {test_loss / len(test_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aebc2f9a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-12T23:18:18.368955Z",
     "iopub.status.busy": "2025-10-12T23:18:18.368427Z",
     "iopub.status.idle": "2025-10-12T23:20:55.290370Z",
     "shell.execute_reply": "2025-10-12T23:20:55.289427Z"
    },
    "papermill": {
     "duration": 164.541246,
     "end_time": "2025-10-12T23:20:55.291726",
     "exception": false,
     "start_time": "2025-10-12T23:18:10.750480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating BLEU: 100%|██████████| 29/29 [02:36<00:00,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " BLEU score: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import sacrebleu\n",
    "\n",
    "references, hypotheses = [], []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Evaluating BLEU\"):\n",
    "        src_texts = [tokenizer.decode(x, skip_special_tokens=True) for x in batch[\"src_input\"]]\n",
    "        tgt_texts = [tokenizer.decode(x, skip_special_tokens=True) for x in batch[\"tgt_label\"]]\n",
    "\n",
    "        for s, t in zip(src_texts, tgt_texts):\n",
    "            pred = translate(s)\n",
    "            references.append(t)\n",
    "            hypotheses.append(pred)\n",
    "\n",
    "bleu = sacrebleu.corpus_bleu(hypotheses, [references])\n",
    "print(f\" BLEU score: {bleu.score:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b780ca7",
   "metadata": {},
   "source": [
    "Cách config đầu tiên train trên 50 epoch nên kết quả tốt hơn, dù d_model và d_embed thấp hơn. Tuy nhiên, khi dùng sarceBLEU để đo hiệu suất của kết quả dịch ở cả 2 config thì vẫn khá thấp ( 0.83 - 1.08).Điều này có thể là do Tokenization thiếu hiệu quả và Kích thước dữ liệu chưa đủ. Cụ thể, việc sử dụng Tokenization dựa trên từ (Word-level Tokenization) đơn giản cho cặp ngôn ngữ phức tạp như Anh-Việt đã tạo ra một bộ từ vựng (Vocabulary) khổng lồ, khiến quá nhiều từ trong bộ dữ liệu EVBCorpus bị gán nhãn là <UNK> (Unknown) khi giới hạn kích thước Vocab, dẫn đến hiện tượng Out-of-Vocabulary (OOV) nghiêm trọng làm mất thông tin ngữ nghĩa và khiến mô hình chỉ có thể dịch các chuỗi vô nghĩa."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 6040691,
     "sourceId": 9845635,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 24504.851402,
   "end_time": "2025-10-12T23:21:04.994625",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-10-12T16:32:40.143223",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0961c0dbae5d4cb0aae718f67dd0e23b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "13e06a0e65124aa4ae204a230ac4cba1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_83cb02c23db6456aa97db2ce468abfb9",
       "placeholder": "​",
       "style": "IPY_MODEL_8c7d8dd6e71d47e69f5ff108cad5df8b",
       "tabbable": null,
       "tooltip": null,
       "value": " 5.07M/5.07M [00:00&lt;00:00, 24.4MB/s]"
      }
     },
     "1517c9a5d60740789e56b1fd4c386a8a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "21d8953df4bb45c88852e8c70d308b36": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2527bf176a0a4177b627900b777076bd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "26acef836fe442c1925fda894707f773": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2f059bd42fd64e088c582559caa1de5d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "35f5db66834d44a28a43eda919fbf370": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3830733c7a21442e9ffa6118a2bb9163": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3836d85c8d5e4760b4dad962014d2a37": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "3d6c3dd00ece40a28b0382c085f80d70": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_da679e6da4654b09bafe177d2643eb9e",
       "max": 5069051,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3836d85c8d5e4760b4dad962014d2a37",
       "tabbable": null,
       "tooltip": null,
       "value": 5069051
      }
     },
     "437819c274b54b7e8232a42bb7a870da": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_4ac672e0beee469f9bd090309268d3d1",
        "IPY_MODEL_3d6c3dd00ece40a28b0382c085f80d70",
        "IPY_MODEL_13e06a0e65124aa4ae204a230ac4cba1"
       ],
       "layout": "IPY_MODEL_78da303eaa3d41e8b345e65b4b8cfe6e",
       "tabbable": null,
       "tooltip": null
      }
     },
     "470ecf9d9db7441e99ec00e31b83e443": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_ba07ada765114c6aa79e40e75431554e",
       "placeholder": "​",
       "style": "IPY_MODEL_9b082752b4994f31b88fb30ed5a1e200",
       "tabbable": null,
       "tooltip": null,
       "value": " 615/615 [00:00&lt;00:00, 71.7kB/s]"
      }
     },
     "4ac672e0beee469f9bd090309268d3d1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_2527bf176a0a4177b627900b777076bd",
       "placeholder": "​",
       "style": "IPY_MODEL_5ce1562c32f347b5949d2ec8eabf9b41",
       "tabbable": null,
       "tooltip": null,
       "value": "sentencepiece.bpe.model: 100%"
      }
     },
     "4fe5d3c2b76a48bfaed7514e1ca11d5b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_8c6bef898c2f4d669fe7574e11705a66",
        "IPY_MODEL_76c67304f59548bca2e0d934e4df753a",
        "IPY_MODEL_e368db4e9ccc4ab1abe12dff6f85aa67"
       ],
       "layout": "IPY_MODEL_1517c9a5d60740789e56b1fd4c386a8a",
       "tabbable": null,
       "tooltip": null
      }
     },
     "52d1643c3bf04e4e88980c8f495db188": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "5ce1562c32f347b5949d2ec8eabf9b41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "5ee4af5d472d447fb712e009774372b9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_b57eb11c63be4df3abf775fbc5859b54",
        "IPY_MODEL_a8bb739f98ef43a882d8ab2f43b9fb29",
        "IPY_MODEL_96776e6069b14f4bb0667c3c3d5012c1"
       ],
       "layout": "IPY_MODEL_35f5db66834d44a28a43eda919fbf370",
       "tabbable": null,
       "tooltip": null
      }
     },
     "62a62fb3f4614757ac18b4c0738defc1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_21d8953df4bb45c88852e8c70d308b36",
       "placeholder": "​",
       "style": "IPY_MODEL_7e21ff2bdfb041929405cb20ac62dc29",
       "tabbable": null,
       "tooltip": null,
       "value": "config.json: 100%"
      }
     },
     "63c3728edc794d4e8d3a49c5f5a56462": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "76c67304f59548bca2e0d934e4df753a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_961d2b2225394d68bdf2f288509af82e",
       "max": 25,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_3830733c7a21442e9ffa6118a2bb9163",
       "tabbable": null,
       "tooltip": null,
       "value": 25
      }
     },
     "78da303eaa3d41e8b345e65b4b8cfe6e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7d6b0f35f6d84e67811c68b2de23f1d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "7e21ff2bdfb041929405cb20ac62dc29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "83cb02c23db6456aa97db2ce468abfb9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "85a944313a8d4c28a62a38d8487410eb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "8c6bef898c2f4d669fe7574e11705a66": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_995b9da21b5242c7b1bc895037324143",
       "placeholder": "​",
       "style": "IPY_MODEL_0961c0dbae5d4cb0aae718f67dd0e23b",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer_config.json: 100%"
      }
     },
     "8c7d8dd6e71d47e69f5ff108cad5df8b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "961d2b2225394d68bdf2f288509af82e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "96776e6069b14f4bb0667c3c3d5012c1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_26acef836fe442c1925fda894707f773",
       "placeholder": "​",
       "style": "IPY_MODEL_c65213ae0380428398b62df511048e88",
       "tabbable": null,
       "tooltip": null,
       "value": " 9.10M/9.10M [00:00&lt;00:00, 17.9MB/s]"
      }
     },
     "98f1a6d1ec4944c1a9507705546ba346": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "995b9da21b5242c7b1bc895037324143": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9b082752b4994f31b88fb30ed5a1e200": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "a8bb739f98ef43a882d8ab2f43b9fb29": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_db8abcdb280844ed8eaca9e120ec4f08",
       "max": 9096718,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_52d1643c3bf04e4e88980c8f495db188",
       "tabbable": null,
       "tooltip": null,
       "value": 9096718
      }
     },
     "b2152cc4a82d4285b10ad67fdd96359f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_85a944313a8d4c28a62a38d8487410eb",
       "max": 615,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_98f1a6d1ec4944c1a9507705546ba346",
       "tabbable": null,
       "tooltip": null,
       "value": 615
      }
     },
     "b57eb11c63be4df3abf775fbc5859b54": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_7d6b0f35f6d84e67811c68b2de23f1d3",
       "placeholder": "​",
       "style": "IPY_MODEL_63c3728edc794d4e8d3a49c5f5a56462",
       "tabbable": null,
       "tooltip": null,
       "value": "tokenizer.json: 100%"
      }
     },
     "ba07ada765114c6aa79e40e75431554e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "c65213ae0380428398b62df511048e88": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "ca002b9787314d17820f38dc99cfba38": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_62a62fb3f4614757ac18b4c0738defc1",
        "IPY_MODEL_b2152cc4a82d4285b10ad67fdd96359f",
        "IPY_MODEL_470ecf9d9db7441e99ec00e31b83e443"
       ],
       "layout": "IPY_MODEL_2f059bd42fd64e088c582559caa1de5d",
       "tabbable": null,
       "tooltip": null
      }
     },
     "da679e6da4654b09bafe177d2643eb9e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "da7535324cd94244848d53388e08ff00": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "db8abcdb280844ed8eaca9e120ec4f08": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "de9e2b4381434eb484b8e759f2654bde": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "e368db4e9ccc4ab1abe12dff6f85aa67": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_de9e2b4381434eb484b8e759f2654bde",
       "placeholder": "​",
       "style": "IPY_MODEL_da7535324cd94244848d53388e08ff00",
       "tabbable": null,
       "tooltip": null,
       "value": " 25.0/25.0 [00:00&lt;00:00, 2.78kB/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
