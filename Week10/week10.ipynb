{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "f65a86d0",
      "metadata": {
        "id": "f65a86d0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import requests\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "d2a901f1",
      "metadata": {
        "id": "d2a901f1"
      },
      "outputs": [],
      "source": [
        "def scrape_webpage(url):\n",
        "    headers = {\n",
        "        \"User-Agent\": (\n",
        "            \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) \"\n",
        "            \"AppleWebKit/537.36 (KHTML, like Gecko) \"\n",
        "            \"Chrome/120.0 Safari/537.36\"\n",
        "        )\n",
        "    }\n",
        "\n",
        "    html = requests.get(url, headers=headers).text\n",
        "    soup = BeautifulSoup(html, \"html.parser\")\n",
        "\n",
        "    paragraphs = soup.find_all(\"p\")\n",
        "    text = \"\\n\".join([p.get_text() for p in paragraphs])\n",
        "\n",
        "    return text\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q faiss-cpu"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ggGY2ut4PILj",
        "outputId": "b8079c5c-1c76-4e05-c62f-a277936f58f8"
      },
      "id": "ggGY2ut4PILj",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m23.6/23.6 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "d441ef05",
      "metadata": {
        "id": "d441ef05"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import faiss\n",
        "import google.generativeai as genai\n",
        "\n",
        "genai.configure(api_key=\"AIzaSyD1Pg3rcz0OCOhuetFZ1s3POs_a5DiWCU0\")\n",
        "\n",
        "def chunk_text(text, chunk_size, overlap):\n",
        "  words=text.split()\n",
        "  chunks=[]\n",
        "  start=0\n",
        "  while start<len(words):\n",
        "    end=start+chunk_size\n",
        "    chunk=\" \".join(words[start:end])\n",
        "    chunks.append(chunk)\n",
        "    start=end-overlap\n",
        "    if start < 0:\n",
        "      break\n",
        "  return chunks\n",
        "def build_faiss(chunks):\n",
        "    vectors = []\n",
        "\n",
        "    for c in chunks:\n",
        "        v = genai.embed_content(\n",
        "            model=\"models/text-embedding-004\",\n",
        "            content=c\n",
        "        )[\"embedding\"]\n",
        "        vectors.append(v)\n",
        "\n",
        "    matrix = np.array(vectors).astype(\"float32\")\n",
        "    dim = matrix.shape[1]\n",
        "    index = faiss.IndexFlatL2(dim)\n",
        "    index.add(matrix)\n",
        "    return index, matrix\n",
        "\n",
        "def search(query, index, chunks, k=3):\n",
        "    q_emb = genai.embed_content(\n",
        "        model=\"models/text-embedding-004\",\n",
        "        content=query\n",
        "    )\n",
        "    q_emb = np.array(q_emb[\"embedding\"]).astype(\"float32\").reshape(1,-1)\n",
        "\n",
        "    D,I = index.search(q_emb, k)\n",
        "    return [chunks[i] for i in I[0]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "fde9e071",
      "metadata": {
        "id": "fde9e071"
      },
      "outputs": [],
      "source": [
        "def answer_with_gemini(question, contexts):\n",
        "    prompt = f\"\"\"\n",
        "Tráº£ lá»i cÃ¢u há»i dá»±a trÃªn context sau:\n",
        "\n",
        "{chr(10).join(contexts)}\n",
        "\n",
        "CÃ¢u há»i: {question}\n",
        "    \"\"\"\n",
        "    model = genai.GenerativeModel(\"gemini-2.5-flash\")\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    url = input(\"Nháº­p URL: \")\n",
        "    print(\"Äang scrape...\")\n",
        "    text = scrape_webpage(url)\n",
        "\n",
        "    print(\"Äang chunk...\")\n",
        "    chunks = chunk_text(text,chunk_size=300, overlap=50)\n",
        "    print(\"Chunks:\", len(chunks))\n",
        "    print(\"Empty chunks:\", [i for i in chunks if len(i.strip()) == 0])\n",
        "\n",
        "\n",
        "    print(\"Äang táº¡o FAISS index...\")\n",
        "    index, _ = build_faiss(chunks)\n",
        "\n",
        "    print(\"\\n=== Sáºµn sÃ ng há»i Ä‘Ã¡p ===\")\n",
        "    while True:\n",
        "        q = input(\"\\nBáº¡n há»i gÃ¬? (gÃµ 'exit' Ä‘á»ƒ thoÃ¡t) \")\n",
        "        if q == \"exit\":\n",
        "            break\n",
        "\n",
        "        contexts = search(q, index, chunks)\n",
        "        answer = answer_with_gemini(q, contexts)\n",
        "        print(\"\\nğŸ‘‰\", answer)\n"
      ],
      "metadata": {
        "id": "lJ2XHJ8QRsZF"
      },
      "id": "lJ2XHJ8QRsZF",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        },
        "id": "gw9sXKz-SkQJ",
        "outputId": "bb144a79-7f23-4e5b-a6ab-3a80542a855f"
      },
      "id": "gw9sXKz-SkQJ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Nháº­p URL: https://en.wikipedia.org/wiki/Yann_LeCun\n",
            "Äang scrape...\n",
            "Äang chunk...\n",
            "Chunks: 5\n",
            "Empty chunks: []\n",
            "Äang táº¡o FAISS index...\n",
            "\n",
            "=== Sáºµn sÃ ng há»i Ä‘Ã¡p ===\n",
            "\n",
            "Báº¡n há»i gÃ¬? (gÃµ 'exit' Ä‘á»ƒ thoÃ¡t) When was Yan LeCun born?\n",
            "\n",
            "ğŸ‘‰ Yann LeCun was born on 8 July 1960.\n",
            "\n",
            "Báº¡n há»i gÃ¬? (gÃµ 'exit' Ä‘á»ƒ thoÃ¡t) how many awards was Yan LeCun received?\n",
            "\n",
            "ğŸ‘‰ Yan LeCun received **16** awards mentioned in the text:\n",
            "\n",
            "1.  Honorary doctorate from IPN in Mexico City (2016)\n",
            "2.  Honorary doctorate from EPFL (2018)\n",
            "3.  Honorary doctorate from UniversitÃ© CÃ´te d'Azur (2021)\n",
            "4.  Honorary doctorate from UniversitÃ  di Siena (2023)\n",
            "5.  Honorary doctorate from Hong Kong University of Science and Technology (2023)\n",
            "6.  IEEE Neural Network Pioneer Award (2014)\n",
            "7.  PAMI Distinguished Researcher Award (2015)\n",
            "8.  IRI Medal (2018)\n",
            "9.  Harold Pender Award (2018)\n",
            "10. Golden Plate Award of the American Academy of Achievement (2019)\n",
            "11. Turing Award (2018, received in March 2019)\n",
            "12. Princess of Asturias Award (2022)\n",
            "13. Chevalier (Knight) of the French Legion of Honour (2023)\n",
            "14. Global Swiss AI Award 2023 (received during WEF 2024)\n",
            "15. VinFuture Prize (The same year as Global Swiss AI Award 2023, implying 2024)\n",
            "16. Queen Elizabeth Prize for Engineering (2025)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gycg6QjrS0le"
      },
      "id": "gycg6QjrS0le",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}